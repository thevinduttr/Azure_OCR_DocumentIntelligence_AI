# ğŸ“„ Document Processing & AI-Based Field Extraction Pipeline

## ğŸš€ Overview

This project automates the processing of customer documents using Azure AI services. It merges multiple PDFs/images into a single PDF, extracts text using Azure Document Intelligence (Layout Model), and classifies each page using Azure OpenAI GPTâ€‘4.1. The system identifies Emirates ID, Driving License, Vehicle Registration (Mulkiya), or Other Document types and extracts structured fields for validation or database use. All paths, keys, and endpoints are fully configurable via YAML files, ensuring the system requires no code modification after deployment.

## ğŸ“¦ Project Structure

```
project-root/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ paths.yml
â”‚   â”œâ”€â”€ azure.yml
â”‚   â”œâ”€â”€ azure_openai.yml
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ document_merger.py
â”‚   â”œâ”€â”€ azure_ocr_client.py
â”‚   â””â”€â”€ document_classifier.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_documents/
â”‚   â”œâ”€â”€ processed_documents/
â”‚   â”œâ”€â”€ ocr_output/
â”‚   â””â”€â”€ ai_output/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_document_merger.py
â”‚   â””â”€â”€ test_azure_ocr_client.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ› ï¸ Installation

```bash
python -m venv venv
venv\Scripts\activate   # Windows
source venv/bin/activate # Linux/Mac
pip install -r requirements.txt
```

## âš™ï¸ Configuration

All configs are stored in `config/`.

### paths.yml
```yaml
paths:
  raw_documents_dir: "data/raw_documents"
  processed_documents_dir: "data/processed_documents"
  processed_filename: "processed_document.pdf"
  ocr_output_dir: "data/ocr_output"
  ai_output_dir: "data/ai_output"
```

### azure.yml
```yaml
azure:
  document_intelligence:
    endpoint: "https://<resource>.cognitiveservices.azure.com/"
    key: "<key>"
    layout_model_id: "prebuilt-layout"
```

### azure_openai.yml
```yaml
azure_openai:
  endpoint: "https://<resource>.openai.azure.com/"
  deployment_name: "gpt-4.1"
  api_key: "<key>"
  api_version: "2025-01-01-preview"
```

## â–¶ï¸ Running the Pipeline

1. Place documents into:
```
data/raw_documents/
```

2. Run:
```bash
python main.py
```

3. Outputs:
- `data/processed_documents/processed_document.pdf`
- `data/ocr_output/..._layout.json`
- `data/ai_output/..._classified.json`

## ğŸ§ª Testing

```bash
pytest -q
```

## ğŸ‘¤ Author

Thevindu Rathnaweera
